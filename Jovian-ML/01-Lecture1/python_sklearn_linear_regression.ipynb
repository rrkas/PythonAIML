{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greater-color",
   "metadata": {
    "id": "greater-color"
   },
   "source": [
    "# Linear Regression with Scikit Learn - Machine Learning with Python\n",
    "\n",
    "This tutorial is a part of [Zero to Data Science Bootcamp by Jovian](https://zerotodatascience.com) and [Machine Learning with Python: Zero to GBMs](https://jovian.ai/learn/machine-learning-with-python-zero-to-gbms)\n",
    "\n",
    "![](https://i.imgur.com/1EzyZvj.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-anaheim",
   "metadata": {
    "id": "framed-anaheim"
   },
   "source": [
    "The following topics are covered in this tutorial:\n",
    "\n",
    "- A typical problem statement for machine learning\n",
    "- Downloading and exploring a dataset for machine learning\n",
    "- Linear regression with one variable using Scikit-learn\n",
    "- Linear regression with multiple variables \n",
    "- Using categorical features for machine learning\n",
    "- Regression coefficients and feature importance\n",
    "- Other models and techniques for regression using Scikit-learn\n",
    "- Applying linear regression to other datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-little",
   "metadata": {
    "id": "asian-little"
   },
   "source": [
    "### How to run the code\n",
    "\n",
    "This tutorial is an executable [Jupyter notebook](https://jupyter.org) hosted on [Jovian](https://www.jovian.ai). You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.\n",
    "\n",
    "#### Option 1: Running using free online resources (1-click, recommended)\n",
    "\n",
    "The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Binder**. You can also select \"Run on Colab\" or \"Run on Kaggle\", but you'll need to create an account on [Google Colab](https://colab.research.google.com) or [Kaggle](https://kaggle.com) to use these platforms.\n",
    "\n",
    "\n",
    "#### Option 2: Running on your computer locally\n",
    "\n",
    "To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
    "\n",
    ">  **Jupyter Notebooks**: This tutorial is a [Jupyter notebook](https://jupyter.org) - a document made of _cells_. Each cell can contain code written in Python or explanations in plain English. You can execute code cells and view the results, e.g., numbers, messages, graphs, tables, files, etc., instantly within the notebook. Jupyter is a powerful platform for experimentation and analysis. Don't be afraid to mess around with the code & break things - you'll learn a lot by encountering and fixing errors. You can use the \"Kernel > Restart & Clear Output\" menu option to clear all outputs and start again from the top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-teens",
   "metadata": {
    "id": "north-teens"
   },
   "source": [
    "## Problem Statement\n",
    "\n",
    "This tutorial takes a practical and coding-focused approach. We'll define the terms _machine learning_ and _linear regression_ in the context of a problem, and later generalize their definitions. We'll work through a typical machine learning problem step-by-step:\n",
    "\n",
    "\n",
    "> **QUESTION**: ACME Insurance Inc. offers affordable health insurance to thousands of customer all over the United States. As the lead data scientist at ACME, **you're tasked with creating an automated system to estimate the annual medical expenditure for new customers**, using information such as their age, sex, BMI, children, smoking habits and region of residence. \n",
    ">\n",
    "> Estimates from your system will be used to determine the annual insurance premium (amount paid every month) offered to the customer. Due to regulatory requirements, you must be able to explain why your system outputs a certain prediction.\n",
    "> \n",
    "> You're given a [CSV file](https://raw.githubusercontent.com/JovianML/opendatasets/master/data/medical-charges.csv) containing verified historical data, consisting of the aforementioned information and the actual medical charges incurred by over 1300 customers. \n",
    "> <img src=\"https://i.imgur.com/87Uw0aG.png\" width=\"480\">\n",
    ">\n",
    "> Dataset source: https://github.com/stedy/Machine-Learning-with-R-datasets\n",
    "\n",
    "\n",
    "**EXERCISE**: Before proceeding further, take a moment to think about how can approach this problem. List five or more ideas that come to your mind below:\n",
    " \n",
    " 1. ???\n",
    " 2. ???\n",
    " 3. ???\n",
    " 4. ???\n",
    " 5. ???\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-fifteen",
   "metadata": {
    "id": "otherwise-fifteen"
   },
   "source": [
    "## Downloading the Data\n",
    "\n",
    "To begin, let's download the data using the `urlretrieve` function from `urllib.request`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-citizenship",
   "metadata": {
    "id": "viral-citizenship"
   },
   "outputs": [],
   "source": [
    "medical_charges_url = 'https://raw.githubusercontent.com/JovianML/opendatasets/master/data/medical-charges.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-shipping",
   "metadata": {
    "id": "hundred-shipping"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-orientation",
   "metadata": {
    "id": "norwegian-orientation",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "urlretrieve(medical_charges_url, 'medical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-blues",
   "metadata": {
    "id": "smart-blues"
   },
   "source": [
    "We can now create a Pandas dataframe using the downloaded file, to view and analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-estonia",
   "metadata": {
    "id": "critical-estonia"
   },
   "outputs": [],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-omega",
   "metadata": {
    "id": "nuclear-omega"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-chaos",
   "metadata": {
    "id": "aware-chaos"
   },
   "outputs": [],
   "source": [
    "medical_df = pd.read_csv('medical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-tracy",
   "metadata": {
    "id": "dependent-tracy",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "medical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-people",
   "metadata": {
    "id": "wrapped-people"
   },
   "source": [
    "The dataset contains 1338 rows and 7 columns. Each row of the dataset contains information about one customer. \n",
    "\n",
    "Our objective is to find a way to estimate the value in the \"charges\" column using the values in the other columns. If we can do so for the historical data, then we should able to estimate charges for new customers too, simply by asking for information like their age, sex, BMI, no. of children, smoking habits and region.\n",
    "\n",
    "Let's check the data type for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-saver",
   "metadata": {
    "id": "established-saver"
   },
   "outputs": [],
   "source": [
    "medical_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-costa",
   "metadata": {
    "id": "searching-costa"
   },
   "source": [
    "Looks like \"age\", \"children\", \"bmi\" ([body mass index](https://en.wikipedia.org/wiki/Body_mass_index)) and \"charges\" are numbers, whereas \"sex\", \"smoker\" and \"region\" are strings (possibly categories). None of the columns contain any missing values, which saves us a fair bit of work!\n",
    "\n",
    "Here are some statistics for the numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-lancaster",
   "metadata": {
    "id": "vertical-lancaster"
   },
   "outputs": [],
   "source": [
    "medical_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-toyota",
   "metadata": {
    "id": "sunrise-toyota"
   },
   "source": [
    "The ranges of values in the numerical columns seem reasonable too (no negative ages!), so we may not have to do much data cleaning or correction. The \"charges\" column seems to be significantly skewed however, as the median (50 percentile) is much lower than the maximum value.\n",
    "\n",
    "\n",
    "> **EXERCISE**: What other inferences can you draw by looking at the table above? Add your inferences below:\n",
    ">\n",
    "> 1. ???\n",
    "> 2. ???\n",
    "> 3. ???\n",
    "> 4. ???\n",
    "> 5. ???\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-found",
   "metadata": {
    "id": "prescribed-found"
   },
   "source": [
    "## Exploratory Analysis and Visualization\n",
    "\n",
    "Let's explore the data by visualizing the distribution of values in some columns of the dataset, and the relationships between \"charges\" and other columns.\n",
    "\n",
    "We'll use libraries Matplotlib, Seaborn and Plotly for visualization. Follow these tutorials to learn how to use these libraries: \n",
    "\n",
    "- https://jovian.ai/aakashns/python-matplotlib-data-visualization\n",
    "- https://jovian.ai/aakashns/interactive-visualization-plotly\n",
    "- https://jovian.ai/aakashns/dataviz-cheatsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-transition",
   "metadata": {
    "id": "adapted-transition"
   },
   "outputs": [],
   "source": [
    "!pip install plotly matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-freight",
   "metadata": {
    "id": "extensive-freight"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-resolution",
   "metadata": {
    "id": "electronic-resolution"
   },
   "source": [
    "The following settings will improve the default style and font sizes for our charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-blond",
   "metadata": {
    "id": "former-blond"
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-arizona",
   "metadata": {
    "id": "attended-arizona"
   },
   "source": [
    "### Age\n",
    "\n",
    "Age is a numeric column. The minimum age in the dataset is 18 and the maximum age is 64. Thus, we can visualize the distribution of age using a histogram with 47 bins (one for each year) and a box plot. We'll use plotly to make the chart interactive, but you can create similar charts using Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-recall",
   "metadata": {
    "id": "spanish-recall"
   },
   "outputs": [],
   "source": [
    "medical_df.age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-adelaide",
   "metadata": {
    "id": "african-adelaide"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(medical_df, \n",
    "                   x='age', \n",
    "                   marginal='box', \n",
    "                   nbins=47, \n",
    "                   title='Distribution of Age')\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-sugar",
   "metadata": {
    "id": "equivalent-sugar"
   },
   "source": [
    "The distribution of ages in the dataset is almost uniform, with 20-30 customers at every age, except for the ages 18 and 19, which seem to have over twice as many customers as other ages. The uniform distribution might arise from the fact that there isn't a big variation in the [number of people of any given age](https://www.statista.com/statistics/241488/population-of-the-us-by-sex-and-age/) (between 18 & 64) in the USA.\n",
    "\n",
    "\n",
    "\n",
    "> **EXERCISE**: Can you explain why there are over twice as many customers with ages 18 and 19, compared to other ages?\n",
    ">\n",
    "> ???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-fellow",
   "metadata": {
    "id": "revised-fellow"
   },
   "source": [
    "### Body Mass Index\n",
    "\n",
    "Let's look at the distribution of BMI (Body Mass Index) of customers, using a histogram and box plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-holly",
   "metadata": {
    "id": "advisory-holly",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(medical_df, \n",
    "                   x='bmi', \n",
    "                   marginal='box', \n",
    "                   color_discrete_sequence=['red'], \n",
    "                   title='Distribution of BMI (Body Mass Index)')\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-conditioning",
   "metadata": {
    "id": "working-conditioning"
   },
   "source": [
    "The measurements of body mass index seem to form a [Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution) centered around the value 30, with a few outliers towards the right. Here's how BMI values can be interpreted ([source](https://study.com/academy/lesson/what-is-bmi-definition-formula-calculation.html)):\n",
    "\n",
    "![](https://i.imgur.com/lh23OiY.jpg)\n",
    "\n",
    "> **EXERCISE**: Can you explain why the distribution of ages forms a uniform distribution while the distribution of BMIs forms a gaussian distribution?\n",
    ">\n",
    "> ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-property",
   "metadata": {
    "id": "optical-property"
   },
   "source": [
    "### Charges\n",
    "\n",
    "Let's visualize the distribution of \"charges\" i.e. the annual medical charges for customers. This is the column we're trying to predict. Let's also use the categorical column \"smoker\" to distinguish the charges for smokers and non-smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-withdrawal",
   "metadata": {
    "id": "according-withdrawal"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(medical_df, \n",
    "                   x='charges', \n",
    "                   marginal='box', \n",
    "                   color='smoker', \n",
    "                   color_discrete_sequence=['green', 'grey'], \n",
    "                   title='Annual Medical Charges')\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-jungle",
   "metadata": {
    "id": "floral-jungle"
   },
   "source": [
    "We can make the following observations from the above graph:\n",
    "\n",
    "* For most customers, the annual medical charges are under \\\\$10,000. Only a small fraction of customer have higher medical expenses, possibly due to accidents, major illnesses and genetic diseases. The distribution follows a \"power law\"\n",
    "* There is a significant difference in medical expenses between smokers and non-smokers. While the median for non-smokers is \\\\$7300, the median for smokers is close to \\\\$35,000.\n",
    "\n",
    "\n",
    "> **EXERCISE**: Visualize the distribution of medical charges in connection with other factors like \"sex\" and \"region\". What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-projection",
   "metadata": {
    "id": "chemical-projection"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(medical_df, \n",
    "                   x='charges', \n",
    "                   marginal='box', \n",
    "                   color='sex', \n",
    "                   title='Annual Medical Charges')\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-gasoline",
   "metadata": {
    "id": "subtle-gasoline"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(medical_df, \n",
    "                   x='charges', \n",
    "                   marginal='box', \n",
    "                   color='region', \n",
    "                   title='Annual Medical Charges')\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-insulin",
   "metadata": {
    "id": "duplicate-insulin"
   },
   "source": [
    "### Smoker\n",
    "\n",
    "Let's visualize the distribution of the \"smoker\" column (containing values \"yes\" and \"no\") using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-portsmouth",
   "metadata": {
    "id": "anticipated-portsmouth"
   },
   "outputs": [],
   "source": [
    "medical_df.smoker.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-frequency",
   "metadata": {
    "id": "capital-frequency"
   },
   "outputs": [],
   "source": [
    "px.histogram(medical_df, x='smoker', color='sex', title='Smoker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-separation",
   "metadata": {
    "id": "large-separation"
   },
   "source": [
    "It appears that 20% of customers have reported that they smoke. Can you verify whether this matches the national average, assuming the data was collected in 2010? We can also see that smoking appears a more common habit among males. Can you verify this?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-swedish",
   "metadata": {
    "id": "light-swedish"
   },
   "source": [
    "> **EXERCISE**: Visualize the distributions of the \"sex\", \"region\" and \"children\" columns and report your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-black",
   "metadata": {
    "id": "strange-black"
   },
   "outputs": [],
   "source": [
    "px.histogram(medical_df, x='region', color='sex', title='Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-cornwall",
   "metadata": {
    "id": "opposed-cornwall"
   },
   "outputs": [],
   "source": [
    "px.histogram(medical_df, x='children', color='sex', title='Smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-japan",
   "metadata": {
    "id": "scheduled-japan"
   },
   "outputs": [],
   "source": [
    "px.histogram(medical_df, x='sex', title='Smoker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-slope",
   "metadata": {
    "id": "objective-slope"
   },
   "source": [
    "Having looked at individual columns, we can now visualize the relationship between \"charges\" (the value we wish to predict) and other columns.\n",
    "\n",
    "### Age and Charges\n",
    "\n",
    "Let's visualize the relationship between \"age\" and \"charges\" using a scatter plot. Each point in the scatter plot represents one customer. We'll also use values in the \"smoker\" column to color the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-proportion",
   "metadata": {
    "id": "occupied-proportion"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(medical_df, \n",
    "                 x='age', \n",
    "                 y='charges', \n",
    "                 color='smoker', \n",
    "                 opacity=0.8, \n",
    "                 hover_data=['sex'], \n",
    "                 title='Age vs. Charges')\n",
    "fig.update_traces(marker_size=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-worth",
   "metadata": {
    "id": "incredible-worth"
   },
   "source": [
    "We can make the following observations from the above chart:\n",
    "\n",
    "* The general trend seems to be that medical charges increase with age, as we might expect. However, there is significant variation at every age, and it's clear that age alone cannot be used to accurately determine medical charges.\n",
    "\n",
    "\n",
    "* We can see three \"clusters\" of points, each of which seems to form a line with an increasing slope:\n",
    "\n",
    "     1. The first and the largest cluster consists primary of presumably \"healthy non-smokers\" who have relatively low medical charges compared to others\n",
    "     \n",
    "     2. The second cluster contains a mix of smokers and non-smokers. It's possible that these are actually two distinct but overlapping clusters: \"non-smokers with medical issues\" and \"smokers without major medical issues\".\n",
    "     \n",
    "     3. The final cluster consists exclusively of smokers, presumably smokers with major medical issues that are possibly related to or worsened by smoking.\n",
    "     \n",
    "\n",
    "> **EXERCISE**: What other inferences can you draw from the above chart?\n",
    ">\n",
    "> 3 clusters (no smokers, light smokers, heavy smokers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-associate",
   "metadata": {
    "id": "personal-associate"
   },
   "source": [
    "### BMI and Charges\n",
    "\n",
    "Let's visualize the relationship between BMI (body mass index) and charges using another scatter plot. Once again, we'll use the values from the \"smoker\" column to color the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-encoding",
   "metadata": {
    "id": "specific-encoding"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(medical_df, \n",
    "                 x='bmi', \n",
    "                 y='charges', \n",
    "                 color='smoker', \n",
    "                 opacity=0.8, \n",
    "                 hover_data=['sex'], \n",
    "                 title='BMI vs. Charges')\n",
    "fig.update_traces(marker_size=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-climb",
   "metadata": {
    "id": "political-climb"
   },
   "source": [
    "It appears that for non-smokers, an increase in BMI doesn't seem to be related to an increase in medical charges. However, medical charges seem to be significantly higher for smokers with a BMI greater than 30.\n",
    "\n",
    "What other insights can you gather from the above graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-wrapping",
   "metadata": {
    "id": "nutritional-wrapping"
   },
   "source": [
    "> **EXERCISE**: Create some more graphs to visualize how the \"charges\" column is related to other columns (\"children\", \"sex\", \"region\" and \"smoker\"). Summarize the insights gathered from these graphs.\n",
    ">\n",
    "> *Hint*: Use violin plots (`px.violin`) and bar plots (`sns.barplot`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-mayor",
   "metadata": {
    "id": "productive-mayor"
   },
   "outputs": [],
   "source": [
    "px.violin(medical_df, x='children', y='charges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-triangle",
   "metadata": {
    "id": "german-triangle"
   },
   "source": [
    "### Correlation\n",
    "\n",
    "As you can tell from the analysis, the values in some columns are more closely related to the values in \"charges\" compared to other columns. E.g. \"age\" and \"charges\" seem to grow together, whereas \"bmi\" and \"charges\" don't.\n",
    "\n",
    "This relationship is often expressed numerically using a measure called the _correlation coefficient_, which can be computed using the `.corr` method of a Pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-current",
   "metadata": {
    "id": "liked-current"
   },
   "outputs": [],
   "source": [
    "medical_df.charges.corr(medical_df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-intent",
   "metadata": {
    "id": "likely-intent"
   },
   "outputs": [],
   "source": [
    "medical_df.charges.corr(medical_df.bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sXMIK94IHc2m",
   "metadata": {
    "id": "sXMIK94IHc2m"
   },
   "outputs": [],
   "source": [
    "medical_df.charges.corr(medical_df.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-affairs",
   "metadata": {
    "id": "assigned-affairs"
   },
   "source": [
    "To compute the correlation for categorical columns, they must first be converted into numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-chosen",
   "metadata": {
    "id": "african-chosen"
   },
   "outputs": [],
   "source": [
    "smoker_values = {'no': 0, 'yes': 1}\n",
    "smoker_numeric = medical_df.smoker.map(smoker_values)\n",
    "medical_df.charges.corr(smoker_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-origin",
   "metadata": {
    "id": "elegant-origin"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "Here's how correlation coefficients can be interpreted ([source](https://statisticsbyjim.com/basics/correlations)):\n",
    "\n",
    "* **Strength**: The greater the absolute value of the correlation coefficient, the stronger the relationship.\n",
    "\n",
    "    * The extreme values of -1 and 1 indicate a perfectly linear relationship where a change in one variable is accompanied by a perfectly consistent change in the other. For these relationships, all of the data points fall on a line. In practice, you won’t see either type of perfect relationship.\n",
    "\n",
    "    * A coefficient of zero represents no linear relationship. As one variable increases, there is no tendency in the other variable to either increase or decrease.\n",
    "    \n",
    "    * When the value is in-between 0 and +1/-1, there is a relationship, but the points don’t all fall on a line. As r approaches -1 or 1, the strength of the relationship increases and the data points tend to fall closer to a line.\n",
    "\n",
    "\n",
    "* **Direction**: The sign of the correlation coefficient represents the direction of the relationship.\n",
    "\n",
    "    * Positive coefficients indicate that when the value of one variable increases, the value of the other variable also tends to increase. Positive relationships produce an upward slope on a scatterplot.\n",
    "    \n",
    "    * Negative coefficients represent cases when the value of one variable increases, the value of the other variable tends to decrease. Negative relationships produce a downward slope.\n",
    "\n",
    "Here's the same relationship expressed visually ([source](https://www.cuemath.com/data/how-to-calculate-correlation-coefficient/)):\n",
    "\n",
    "<img src=\"https://i.imgur.com/3XUpDlw.png\" width=\"360\">\n",
    "\n",
    "The correlation coefficient has the following formula:\n",
    "\n",
    "<img src=\"https://i.imgur.com/unapugP.png\" width=\"360\">\n",
    "\n",
    "You can learn more about the mathematical definition and geometric interpretation of correlation here: https://www.youtube.com/watch?v=xZ_z8KWkhXE\n",
    "\n",
    "Pandas dataframes also provide a `.corr` method to compute the correlation coefficients between all pairs of numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-supply",
   "metadata": {
    "id": "relative-supply"
   },
   "outputs": [],
   "source": [
    "medical_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-portuguese",
   "metadata": {
    "id": "organized-portuguese"
   },
   "source": [
    "The result of `.corr` is called a correlation matrix and is often visualized using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-cloud",
   "metadata": {
    "id": "collect-cloud"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(medical_df.corr(), cmap='Reds', annot=True)\n",
    "plt.title('Correlation Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-stack",
   "metadata": {
    "id": "bacterial-stack"
   },
   "source": [
    "**Correlation vs causation fallacy:** Note that a high correlation cannot be used to interpret a cause-effect relationship between features. Two features $X$ and $Y$ can be correlated if $X$ causes $Y$ or if $Y$ causes $X$, or if both are caused independently by some other factor $Z$, and the correlation will no longer hold true if one of the cause-effect relationships is broken. It's also possible that $X$ are $Y$ simply appear to be correlated because the sample is too small. \n",
    "\n",
    "While this may seem obvious, computers can't differentiate between correlation and causation, and decisions based on automated system can often have major consequences on society, so it's important to study why automated systems lead to a given result. Determining cause-effect relationships requires human insight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-evaluation",
   "metadata": {
    "id": "encouraging-evaluation"
   },
   "source": [
    "## Linear Regression using a Single Feature\n",
    "\n",
    "We now know that the \"smoker\" and \"age\" columns have the strongest correlation with \"charges\". Let's try to find a way of estimating the value of \"charges\" using the value of \"age\" for non-smokers. First, let's create a data frame containing just the data for non-smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-colorado",
   "metadata": {
    "id": "spiritual-colorado"
   },
   "outputs": [],
   "source": [
    "non_smoker_df = medical_df[medical_df.smoker == 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-joyce",
   "metadata": {
    "id": "injured-joyce"
   },
   "source": [
    "Next, let's visualize the relationship between \"age\" and \"charges\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-mainstream",
   "metadata": {
    "id": "acute-mainstream"
   },
   "outputs": [],
   "source": [
    "plt.title('Age vs. Charges')\n",
    "sns.scatterplot(data=non_smoker_df, x='age', y='charges', alpha=0.7, s=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-quality",
   "metadata": {
    "id": "affiliated-quality"
   },
   "source": [
    "Apart from a few exceptions, the points seem to form a line. We'll try and \"fit\" a line using this points, and use the line to predict charges for a given age. A line on the X&Y coordinates has the following formula:\n",
    "\n",
    "$y = wx + b$\n",
    "\n",
    "The line is characterized two numbers: $w$ (called \"slope\") and $b$ (called \"intercept\"). \n",
    "\n",
    "### Model\n",
    "\n",
    "In the above case, the x axis shows \"age\" and the y axis shows \"charges\". Thus, we're assume the following relationship between the two:\n",
    "\n",
    "$charges = w \\times age + b$\n",
    "\n",
    "We'll try determine $w$ and $b$ for the line that best fits the data. \n",
    "\n",
    "* This technique is called _linear regression_, and we call the above equation a _linear regression model_, because it models the relationship between \"age\" and \"charges\" as a straight line. \n",
    "\n",
    "* The numbers $w$ and $b$ are called the _parameters_ or _weights_ of the model.\n",
    "\n",
    "* The values in the \"age\" column of the dataset are called the _inputs_ to the model and the values in the charges column are called \"targets\". \n",
    "\n",
    "Let define a helper function `estimate_charges`, to compute $charges$, given $age$, $w$ and $b$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-capture",
   "metadata": {
    "id": "diverse-capture"
   },
   "outputs": [],
   "source": [
    "def estimate_charges(age, w, b):\n",
    "    return w * age + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-wages",
   "metadata": {
    "id": "shaped-wages"
   },
   "source": [
    "The `estimate_charges` function is our very first _model_.\n",
    "\n",
    "Let's _guess_ the values for $w$ and $b$ and use them to estimate the value for charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-navigation",
   "metadata": {
    "id": "fallen-navigation"
   },
   "outputs": [],
   "source": [
    "w = 50\n",
    "b = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-matrix",
   "metadata": {
    "id": "rising-matrix"
   },
   "outputs": [],
   "source": [
    "ages = non_smoker_df.age\n",
    "estimated_charges = estimate_charges(ages, w, b)\n",
    "estimated_charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-spice",
   "metadata": {
    "id": "failing-spice"
   },
   "source": [
    "We can plot the estimated charges using a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-parker",
   "metadata": {
    "id": "wrong-parker"
   },
   "outputs": [],
   "source": [
    "plt.plot(ages, estimated_charges, 'r-o');\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Estimated Charges');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-howard",
   "metadata": {
    "id": "instructional-howard"
   },
   "source": [
    "As expected, the points lie on a straight line. \n",
    "\n",
    "We can overlay this line on the actual data, so see how well our _model_ fits the _data_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-modification",
   "metadata": {
    "id": "injured-modification"
   },
   "outputs": [],
   "source": [
    "target = non_smoker_df.charges\n",
    "\n",
    "plt.plot(ages, estimated_charges, 'r', alpha=0.9);\n",
    "plt.scatter(ages, target, s=8,alpha=0.8);\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Charges')\n",
    "plt.legend(['Estimate', 'Actual']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-silver",
   "metadata": {
    "id": "modern-silver"
   },
   "source": [
    "Clearly, the our estimates are quite poor and the line does not \"fit\" the data. However, we can try different values of $w$ and $b$ to move the line around. Let's define a helper function `try_parameters` which takes `w` and `b` as inputs and creates the above plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-cemetery",
   "metadata": {
    "id": "recognized-cemetery"
   },
   "outputs": [],
   "source": [
    "def try_parameters(w, b):\n",
    "    ages = non_smoker_df.age\n",
    "    target = non_smoker_df.charges\n",
    "    \n",
    "    estimated_charges = estimate_charges(ages, w, b)\n",
    "    \n",
    "    plt.plot(ages, estimated_charges, 'r', alpha=0.9);\n",
    "    plt.scatter(ages, target, s=8,alpha=0.8);\n",
    "    plt.xlabel('Age');\n",
    "    plt.ylabel('Charges')\n",
    "    plt.legend(['Estimate', 'Actual']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-spirituality",
   "metadata": {
    "id": "announced-spirituality"
   },
   "outputs": [],
   "source": [
    "try_parameters(60, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-ecuador",
   "metadata": {
    "id": "vocal-ecuador",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try_parameters(400, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-completion",
   "metadata": {
    "id": "colonial-completion"
   },
   "source": [
    "> **EXERCISE**: Try various values of $w$ and $b$ to find a line that best fits the data. What is the effect of changing the value of $w$? What is the effect of changing $b$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-military",
   "metadata": {
    "id": "aging-military"
   },
   "outputs": [],
   "source": [
    "try_parameters(270, -3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-belle",
   "metadata": {
    "id": "related-belle"
   },
   "source": [
    "As we change the values, of $w$ and $b$ manually, trying to move the line visually closer to the points, we are _learning_ the approximate relationship between \"age\" and \"charges\". \n",
    "\n",
    "Wouldn't it be nice if a computer could try several different values of `w` and `b` and _learn_ the relationship between \"age\" and \"charges\"? To do this, we need to solve a couple of problems:\n",
    "\n",
    "1. We need a way to measure numerically how well the line fits the points.\n",
    "\n",
    "2. Once the \"measure of fit\" has been computed, we need a way to modify `w` and `b` to improve the the fit.\n",
    "\n",
    "If we can solve the above problems, it should be possible for a computer to determine `w` and `b` for the best fit line, starting from a random guess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-draft",
   "metadata": {
    "id": "jewish-draft"
   },
   "source": [
    "### Loss/Cost Function\n",
    "\n",
    "We can compare our model's predictions with the actual targets using the following method:\n",
    "\n",
    "* Calculate the difference between the targets and predictions (the differenced is called the \"residual\")\n",
    "* Square all elements of the difference matrix to remove negative values.\n",
    "* Calculate the average of the elements in the resulting matrix.\n",
    "* Take the square root of the result\n",
    "\n",
    "The result is a single number, known as the **root mean squared error** (RMSE). The above description can be stated mathematically as follows: \n",
    "\n",
    "<img src=\"https://i.imgur.com/WCanPkA.png\" width=\"360\">\n",
    "\n",
    "Geometrically, the residuals can be visualized as follows:\n",
    "\n",
    "<img src=\"https://i.imgur.com/ll3NL80.png\" width=\"420\">\n",
    "\n",
    "Let's define a function to compute the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-airport",
   "metadata": {
    "id": "alpine-airport"
   },
   "outputs": [],
   "source": [
    "!pip install numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-cigarette",
   "metadata": {
    "id": "available-cigarette"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-breast",
   "metadata": {
    "id": "adverse-breast"
   },
   "outputs": [],
   "source": [
    "def rmse(targets, predictions):\n",
    "    return np.sqrt(np.mean(np.square(targets - predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-resort",
   "metadata": {
    "id": "classical-resort"
   },
   "source": [
    "Let's compute the RMSE for our model with a sample set of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-quantity",
   "metadata": {
    "id": "rough-quantity"
   },
   "outputs": [],
   "source": [
    "w = 50\n",
    "b = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-regression",
   "metadata": {
    "id": "floating-regression"
   },
   "outputs": [],
   "source": [
    "try_parameters(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-armstrong",
   "metadata": {
    "id": "recorded-armstrong"
   },
   "outputs": [],
   "source": [
    "targets = non_smoker_df['charges']\n",
    "predicted = estimate_charges(non_smoker_df.age, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-alert",
   "metadata": {
    "id": "descending-alert"
   },
   "outputs": [],
   "source": [
    "rmse(targets, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-pastor",
   "metadata": {
    "id": "beautiful-pastor"
   },
   "source": [
    "Here's how we can interpret the above number: *On average, each element in the prediction differs from the actual target by \\\\$8461*. \n",
    "\n",
    "The result is called the *loss* because it indicates how bad the model is at predicting the target variables. It represents information loss in the model: the lower the loss, the better the model.\n",
    "\n",
    "Let's modify the `try_parameters` functions to also display the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-allergy",
   "metadata": {
    "id": "radical-allergy"
   },
   "outputs": [],
   "source": [
    "def try_parameters(w, b):\n",
    "    ages = non_smoker_df.age\n",
    "    target = non_smoker_df.charges\n",
    "    predictions = estimate_charges(ages, w, b)\n",
    "    \n",
    "    plt.plot(ages, predictions, 'r', alpha=0.9);\n",
    "    plt.scatter(ages, target, s=8,alpha=0.8);\n",
    "    plt.xlabel('Age');\n",
    "    plt.ylabel('Charges')\n",
    "    plt.legend(['Prediction', 'Actual']);\n",
    "    \n",
    "    loss = rmse(target, predictions)\n",
    "    print(\"RMSE Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-peninsula",
   "metadata": {
    "id": "worthy-peninsula"
   },
   "outputs": [],
   "source": [
    "try_parameters(50, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-outside",
   "metadata": {
    "id": "fixed-outside"
   },
   "source": [
    "> **EXERCISE**: Try different values of $w$ and $b$ to minimize the RMSE loss. What's the lowest value of loss you are able to achieve? Can you come with a general strategy for finding better values of $w$ and $b$ by trial and error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-shade",
   "metadata": {
    "id": "minor-shade"
   },
   "outputs": [],
   "source": [
    "try_parameters(270, -3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-heart",
   "metadata": {
    "id": "jewish-heart"
   },
   "source": [
    "### Optimizer\n",
    "\n",
    "Next, we need a strategy to modify weights `w` and `b` to reduce the loss and improve the \"fit\" of the line to the data.\n",
    "\n",
    "* Ordinary Least Squares: https://www.youtube.com/watch?v=szXbuO3bVRk (better for smaller datasets)\n",
    "* Stochastic gradient descent: https://www.youtube.com/watch?v=sDv4f4s2SB8 (better for larger datasets)\n",
    "\n",
    "Both of these have the same objective: to minimize the loss, however, while ordinary least squares directly computes the best values for `w` and `b` using matrix operations, while gradient descent uses a iterative approach, starting with a random values of `w` and `b` and slowly improving them using derivatives. \n",
    "\n",
    "Here's a visualization of how gradient descent works:\n",
    "\n",
    "![](https://miro.medium.com/max/1728/1*NO-YvpHHadk5lLxtg4Gfrw.gif)\n",
    "\n",
    "Doesn't it look similar to our own strategy of gradually moving the line closer to the points?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-witch",
   "metadata": {
    "id": "waiting-witch"
   },
   "source": [
    "### Linear Regression using Scikit-learn\n",
    "\n",
    "In practice, you'll never need to implement either of the above methods yourself. You can use a library like `scikit-learn` to do this for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-bolivia",
   "metadata": {
    "id": "rough-bolivia"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-teens",
   "metadata": {
    "id": "nuclear-teens"
   },
   "source": [
    "Let's use the `LinearRegression` class from `scikit-learn` to find the best fit line for \"age\" vs. \"charges\" using the ordinary least squares optimization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-quality",
   "metadata": {
    "id": "medieval-quality"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-grain",
   "metadata": {
    "id": "communist-grain"
   },
   "source": [
    "First, we create a new model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-directory",
   "metadata": {
    "id": "honest-directory"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-reliance",
   "metadata": {
    "id": "victorian-reliance"
   },
   "source": [
    "Next, we can use the `fit` method of the model to find the best fit line for the inputs and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-cruise",
   "metadata": {
    "id": "extensive-cruise"
   },
   "outputs": [],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-basics",
   "metadata": {
    "id": "spectacular-basics"
   },
   "source": [
    "Not that the input `X` must be a 2-d array, so we'll need to pass a dataframe, instead of a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-somewhere",
   "metadata": {
    "id": "western-somewhere"
   },
   "outputs": [],
   "source": [
    "inputs = non_smoker_df[['age']]\n",
    "targets = non_smoker_df.charges\n",
    "print('inputs.shape :', inputs.shape)\n",
    "print('targes.shape :', targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-middle",
   "metadata": {
    "id": "cloudy-middle"
   },
   "source": [
    "Let's fit the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-capture",
   "metadata": {
    "id": "pediatric-capture"
   },
   "outputs": [],
   "source": [
    "model.fit(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-pilot",
   "metadata": {
    "id": "regulated-pilot"
   },
   "source": [
    "We can now make predictions using the model. Let's try predicting the charges for the ages 23, 37 and 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-picking",
   "metadata": {
    "id": "short-picking"
   },
   "outputs": [],
   "source": [
    "model.predict(np.array([[23], \n",
    "                        [37], \n",
    "                        [61]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-gender",
   "metadata": {
    "id": "smoking-gender"
   },
   "source": [
    "Do these values seem reasonable? Compare them with the scatter plot above.\n",
    "\n",
    "Let compute the predictions for the entire set of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-timeline",
   "metadata": {
    "id": "pregnant-timeline"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-medline",
   "metadata": {
    "id": "crude-medline"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-harassment",
   "metadata": {
    "id": "worthy-harassment"
   },
   "source": [
    "Let's compute the RMSE loss to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-chick",
   "metadata": {
    "id": "bound-chick"
   },
   "outputs": [],
   "source": [
    "rmse(targets, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-lithuania",
   "metadata": {
    "id": "graphic-lithuania"
   },
   "source": [
    "Seems like our prediction is off by $4000 on average, which is not too bad considering the fact that there are several outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-hello",
   "metadata": {
    "id": "ongoing-hello"
   },
   "source": [
    "The parameters of the model are stored in the `coef_` and `intercept_` properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-modification",
   "metadata": {
    "id": "eligible-modification"
   },
   "outputs": [],
   "source": [
    "# w\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-project",
   "metadata": {
    "id": "small-project"
   },
   "outputs": [],
   "source": [
    "# b\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-carbon",
   "metadata": {
    "id": "ethical-carbon"
   },
   "outputs": [],
   "source": [
    "try_parameters(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-pendant",
   "metadata": {
    "id": "flying-pendant"
   },
   "source": [
    "Indeed the line is quite close to the points. It is slightly above the cluster of points, because it's also trying to account for the outliers. \n",
    "\n",
    "> **EXERCISE**: Use the [`SGDRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html) class from `scikit-learn` to train a model using the stochastic gradient descent technique. Make predictions and compute the loss. Do you see any difference in the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-respect",
   "metadata": {
    "id": "everyday-respect"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "model2 = LinearRegression()\n",
    "inputs = non_smoker_df[['age']]\n",
    "targets = non_smoker_df.charges\n",
    "print('inputs.shape :', inputs.shape)\n",
    "print('targes.shape :', targets.shape)\n",
    "model2.fit(inputs, targets)\n",
    "model2.predict(np.array([[23], [37], [61]]))\n",
    "rmse(targets, predictions)\n",
    "print('coef (w):', model.coef_)\n",
    "print('intercept(b):', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-governor",
   "metadata": {
    "id": "legal-governor"
   },
   "source": [
    "### Machine Learning\n",
    "\n",
    "Congratulations, you've just trained your first _machine learning model!_ Machine learning is simply the process of computing the best parameters to model the relationship between some feature and targets. \n",
    "\n",
    "Every machine learning problem has three components:\n",
    "\n",
    "1. **Model**\n",
    "\n",
    "2. **Cost Function**\n",
    "\n",
    "3. **Optimizer**\n",
    "\n",
    "We'll look at several examples of each of the above in future tutorials. Here's how the relationship between these three components can be visualized:\n",
    "\n",
    "<img src=\"https://www.deepnetts.com/blog/wp-content/uploads/2019/02/SupervisedLearning.png\" width=\"480\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-battlefield",
   "metadata": {
    "id": "parental-battlefield"
   },
   "source": [
    "As we've seen above, it takes just a few lines of code to train a machine learning model using `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-coupon",
   "metadata": {
    "id": "modern-coupon"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = non_smoker_df[['age']], non_smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-nitrogen",
   "metadata": {
    "id": "sitting-nitrogen"
   },
   "source": [
    "## Linear Regression using Multiple Features\n",
    "\n",
    "So far, we've used on the \"age\" feature to estimate \"charges\". Adding another feature like \"bmi\" is fairly straightforward. We simply assume the following relationship:\n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + b$\n",
    "\n",
    "We need to change just one line of code to include the BMI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-falls",
   "metadata": {
    "id": "exciting-falls"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = non_smoker_df[['age', 'bmi']], non_smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-physiology",
   "metadata": {
    "id": "buried-physiology"
   },
   "source": [
    "As you can see, adding the BMI doesn't seem to reduce the loss by much, as the BMI has a very weak correlation with charges, especially for non smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-south",
   "metadata": {
    "id": "bulgarian-south"
   },
   "outputs": [],
   "source": [
    "non_smoker_df.charges.corr(non_smoker_df.bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-syndication",
   "metadata": {
    "id": "hearing-syndication"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(non_smoker_df, x='bmi', y='charges', title='BMI vs. Charges')\n",
    "fig.update_traces(marker_size=5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-helping",
   "metadata": {
    "id": "experimental-helping"
   },
   "source": [
    "We can also visualize the relationship between all 3 variables \"age\", \"bmi\" and \"charges\" using a 3D scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-disposition",
   "metadata": {
    "id": "bibliographic-disposition"
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(non_smoker_df, x='age', y='bmi', z='charges')\n",
    "fig.update_traces(marker_size=3, marker_opacity=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-football",
   "metadata": {
    "id": "original-football"
   },
   "source": [
    "You can see that it's harder to interpret a 3D scatter plot compared to a 2D scatter plot. As we add more features, it becomes impossible to visualize all feature at once, which is why we use measures like correlation and loss. \n",
    "\n",
    "Let's also check the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-kennedy",
   "metadata": {
    "id": "afraid-kennedy"
   },
   "outputs": [],
   "source": [
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-rapid",
   "metadata": {
    "id": "unnecessary-rapid"
   },
   "source": [
    "Clearly, BMI has a much lower weightage, and you can see why. It has a tiny contribution, and even that is probably accidental. This is an important thing to keep in mind: you can't find a relationship that doesn't exist, no matter what machine learning technique or optimization algorithm you apply. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-dublin",
   "metadata": {
    "id": "adaptive-dublin"
   },
   "source": [
    "> **EXERCISE**: Train a linear regression model to estimate charges using BMI alone. Do you expect it to be better or worse than the previously trained models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-movie",
   "metadata": {
    "id": "contrary-movie"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = non_smoker_df[['bmi']], non_smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-notification",
   "metadata": {
    "id": "sensitive-notification"
   },
   "source": [
    "Let's go one step further, and add the final numeric column: \"children\", which seems to have some correlation with \"charges\".\n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + w_3 \\times charges + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-jonathan",
   "metadata": {
    "id": "anonymous-jonathan"
   },
   "outputs": [],
   "source": [
    "non_smoker_df.charges.corr(non_smoker_df.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-quarter",
   "metadata": {
    "id": "cognitive-quarter"
   },
   "outputs": [],
   "source": [
    "fig = px.strip(non_smoker_df, x='children', y='charges', title= \"Children vs. Charges\")\n",
    "fig.update_traces(marker_size=4, marker_opacity=0.7)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-supplement",
   "metadata": {
    "id": "premium-supplement"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = non_smoker_df[['age', 'bmi', 'children']], non_smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-douglas",
   "metadata": {
    "id": "strange-douglas"
   },
   "source": [
    "Once again, we don't see a big reduction in the loss, even though it's greater than in the case of BMI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-lafayette",
   "metadata": {
    "id": "danish-lafayette"
   },
   "source": [
    "> **EXERCISE**: Repeat the steps is this section to train a linear regression model to estimate medical charges for smokers. Visualize the targets and predictions, and compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-growing",
   "metadata": {
    "id": "authorized-growing"
   },
   "outputs": [],
   "source": [
    "smoker_df = medical_df[medical_df.smoker == 'yes']\n",
    "\n",
    "# Create inputs and targets\n",
    "inputs, targets = smoker_df[['age', 'bmi']], smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-estimate",
   "metadata": {
    "id": "prospective-estimate"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = medical_df[['age', 'bmi', 'children']], medical_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-denmark",
   "metadata": {
    "id": "international-denmark"
   },
   "source": [
    "## Using Categorical Features for Machine Learning\n",
    "\n",
    "So far we've been using only numeric columns, since we can only perform computations with numbers. If we could use categorical columns like \"smoker\", we can train a single model for the entire dataset.\n",
    "\n",
    "To use the categorical columns, we simply need to convert them to numbers. There are three common techniques for doing this:\n",
    "\n",
    "1. If a categorical column has just two categories (it's called a binary category), then we can replace their values with 0 and 1.\n",
    "2. If a categorical column has more than 2 categories, we can perform one-hot encoding i.e. create a new column for each category with 1s and 0s.\n",
    "3. If the categories have a natural order (e.g. cold, neutral, warm, hot), then they can be converted to numbers (e.g. 1, 2, 3, 4) preserving the order. These are called ordinals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-table",
   "metadata": {
    "id": "wireless-table"
   },
   "source": [
    "## Binary Categories\n",
    "\n",
    "The \"smoker\" category has just two values \"yes\" and \"no\". Let's create a new column \"smoker_code\" containing 0 for \"no\" and 1 for \"yes\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-condition",
   "metadata": {
    "id": "senior-condition"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=medical_df, x='smoker', y='charges');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-wireless",
   "metadata": {
    "id": "developed-wireless"
   },
   "outputs": [],
   "source": [
    "smoker_codes = {'no': 0, 'yes': 1}\n",
    "medical_df['smoker_code'] = medical_df.smoker.map(smoker_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-fusion",
   "metadata": {
    "id": "pressing-fusion"
   },
   "outputs": [],
   "source": [
    "medical_df.charges.corr(medical_df.smoker_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-wedding",
   "metadata": {
    "id": "religious-wedding"
   },
   "outputs": [],
   "source": [
    "medical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-venice",
   "metadata": {
    "id": "adolescent-venice"
   },
   "source": [
    "We can now use the `smoker_df` column for linear regression.\n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + w_3 \\times charges + w_4 \\times smoker + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-semiconductor",
   "metadata": {
    "id": "greatest-semiconductor"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = medical_df[['age', 'bmi', 'children', 'smoker_code']], medical_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-offense",
   "metadata": {
    "id": "iraqi-offense"
   },
   "source": [
    "The loss reduces from `11355` to `6056`, almost by 50%! This is an important lesson: never ignore categorical data.\n",
    "\n",
    "\n",
    "Let's try adding the \"sex\" column as well.\n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + w_3 \\times charges + w_4 \\times smoker + w_5 \\times sex + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-marker",
   "metadata": {
    "id": "growing-marker"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=medical_df, x='sex', y='charges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-complexity",
   "metadata": {
    "id": "sublime-complexity"
   },
   "outputs": [],
   "source": [
    "sex_codes = {'female': 0, 'male': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-destruction",
   "metadata": {
    "id": "cathedral-destruction"
   },
   "outputs": [],
   "source": [
    "medical_df['sex_code'] = medical_df.sex.map(sex_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-diary",
   "metadata": {
    "id": "tracked-diary"
   },
   "outputs": [],
   "source": [
    "medical_df.charges.corr(medical_df.sex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-actor",
   "metadata": {
    "id": "dynamic-actor"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "inputs, targets = medical_df[['age', 'bmi', 'children', 'smoker_code', 'sex_code']], medical_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-practitioner",
   "metadata": {
    "id": "operational-practitioner"
   },
   "source": [
    "As you might expect, this does have a significant impact on the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-incentive",
   "metadata": {
    "id": "competent-incentive"
   },
   "source": [
    "\n",
    "### One-hot Encoding\n",
    "\n",
    "The \"region\" column contains 4 values, so we'll need to use hot encoding and create a new column for each region.\n",
    "\n",
    "![](https://i.imgur.com/n8GuiOO.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-breed",
   "metadata": {
    "id": "nuclear-breed"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=medical_df, x='region', y='charges');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-thailand",
   "metadata": {
    "id": "victorian-thailand"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(medical_df[['region']])\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-budapest",
   "metadata": {
    "id": "raising-budapest"
   },
   "outputs": [],
   "source": [
    "one_hot = enc.transform(medical_df[['region']]).toarray()\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-committee",
   "metadata": {
    "id": "sacred-committee"
   },
   "outputs": [],
   "source": [
    "medical_df[['northeast', 'northwest', 'southeast', 'southwest']] = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-montgomery",
   "metadata": {
    "id": "southwest-montgomery"
   },
   "outputs": [],
   "source": [
    "medical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-homework",
   "metadata": {
    "id": "spare-homework"
   },
   "source": [
    "Let's include the region columns into our linear regression model.\n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + w_3 \\times charges + w_4 \\times smoker + w_5 \\times sex + w_6 \\times northeast + w_7 \\times northwest + w_8 \\times southeast + w_9 \\times southwest + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-doctrine",
   "metadata": {
    "id": "cross-doctrine"
   },
   "outputs": [],
   "source": [
    "# Create inputs and targets\n",
    "input_cols = ['age', 'bmi', 'children', 'smoker_code', 'sex_code', 'northeast', 'northwest', 'southeast', 'southwest']\n",
    "inputs, targets = medical_df[input_cols], medical_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-moment",
   "metadata": {
    "id": "retained-moment"
   },
   "source": [
    "Once again, this leads to a fairly small reduction in the loss. \n",
    "\n",
    "> **EXERCISE**: Are two separate linear regression models, one for smokers and one of non-smokers, better than a single linear regression model? Why or why not? Try it out and see if you can justify your answer with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-speed",
   "metadata": {
    "id": "excellent-speed"
   },
   "outputs": [],
   "source": [
    "non_smoker_df = medical_df[medical_df.smoker_code==0]\n",
    "\n",
    "# Create inputs and targets\n",
    "input_cols = ['age', 'bmi', 'children', 'smoker_code', 'sex_code', 'northeast', 'northwest', 'southeast', 'southwest']\n",
    "inputs, targets = non_smoker_df[input_cols], non_smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-evaluation",
   "metadata": {
    "id": "hearing-evaluation"
   },
   "outputs": [],
   "source": [
    "smoker_df = medical_df[medical_df.smoker_code==1]\n",
    "\n",
    "# Create inputs and targets\n",
    "input_cols = ['age', 'bmi', 'children', 'smoker_code', 'sex_code', 'northeast', 'northwest', 'southeast', 'southwest']\n",
    "inputs, targets = smoker_df[input_cols], smoker_df['charges']\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-boston",
   "metadata": {
    "id": "expressed-boston"
   },
   "source": [
    "## Model Improvements\n",
    "\n",
    "Let's discuss and apply some more improvements to our model.\n",
    "\n",
    "### Feature Scaling\n",
    "\n",
    "Recall that due to regulatory requirements, we also need to explain the rationale behind the predictions our model. \n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + w_3 \\times charges + w_4 \\times smoker + w_5 \\times sex + w_6 \\times northeast + w_7 \\times northwest + w_8 \\times southeast + w_9 \\times southwest + b$\n",
    "\n",
    "To compare the importance of each feature in the model, our first instinct might be to compare their weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-focus",
   "metadata": {
    "id": "hired-focus"
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-brake",
   "metadata": {
    "id": "satisfied-brake"
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-dodge",
   "metadata": {
    "id": "noted-dodge"
   },
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame({\n",
    "    'feature': np.append(input_cols, 1),\n",
    "    'weight': np.append(model.coef_, model.intercept_)\n",
    "})\n",
    "weights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-laser",
   "metadata": {
    "id": "transparent-laser"
   },
   "source": [
    "While it seems like BMI and the \"northeast\" have a higher weight than age, keep in mind that the range of values for BMI is limited (15 to 40) and the \"northeast\" column only takes the values 0 and 1.\n",
    "\n",
    "Because different columns have different ranges, we run into two issues:\n",
    "\n",
    "1. We can't compare the weights of different column to identify which features are important\n",
    "2. A column with a larger range of inputs may disproportionately affect the loss and dominate the optimization process.\n",
    "\n",
    "For this reason, it's common practice to scale (or standardize) the values in numeric column by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "![](https://i.imgur.com/dT5fLFI.png)\n",
    "\n",
    "We can apply scaling using the StandardScaler class from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-wesley",
   "metadata": {
    "id": "relevant-wesley"
   },
   "outputs": [],
   "source": [
    "medical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-inspiration",
   "metadata": {
    "id": "convinced-inspiration"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-reviewer",
   "metadata": {
    "id": "baking-reviewer"
   },
   "outputs": [],
   "source": [
    "numeric_cols = ['age', 'bmi', 'children'] \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(medical_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-plastic",
   "metadata": {
    "id": "alpha-plastic"
   },
   "outputs": [],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-moment",
   "metadata": {
    "id": "digital-moment"
   },
   "outputs": [],
   "source": [
    "scaler.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-harbor",
   "metadata": {
    "id": "innovative-harbor"
   },
   "source": [
    "We can now scale data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-runner",
   "metadata": {
    "id": "exterior-runner"
   },
   "outputs": [],
   "source": [
    "scaled_inputs = scaler.transform(medical_df[numeric_cols])\n",
    "scaled_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-newark",
   "metadata": {
    "id": "subsequent-newark"
   },
   "source": [
    "These can now we combined with the categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-globe",
   "metadata": {
    "id": "alternative-globe"
   },
   "outputs": [],
   "source": [
    "cat_cols = ['smoker_code', 'sex_code', 'northeast', 'northwest', 'southeast', 'southwest']\n",
    "categorical_data = medical_df[cat_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-organization",
   "metadata": {
    "id": "constitutional-organization"
   },
   "outputs": [],
   "source": [
    "inputs = np.concatenate((scaled_inputs, categorical_data), axis=1)\n",
    "targets = medical_df.charges\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs, targets)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(inputs)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets, predictions)\n",
    "print('Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-beauty",
   "metadata": {
    "id": "cooperative-beauty"
   },
   "source": [
    "We can now compare the weights in the formula:\n",
    "\n",
    "$charges = w_1 \\times age + w_2 \\times bmi + w_3 \\times charges + w_4 \\times smoker + w_5 \\times sex + w_6 \\times northeast + w_7 \\times northwest + w_8 \\times southeast + w_9 \\times southwest + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-token",
   "metadata": {
    "id": "australian-token"
   },
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame({\n",
    "    'feature': np.append(numeric_cols + cat_cols, 1),\n",
    "    'weight': np.append(model.coef_, model.intercept_)\n",
    "})\n",
    "weights_df.sort_values('weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-proof",
   "metadata": {
    "id": "technological-proof"
   },
   "source": [
    "As you can see now, the most important feature are:\n",
    "\n",
    "1. Smoker\n",
    "2. Age\n",
    "3. BMI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-nitrogen",
   "metadata": {
    "id": "rural-nitrogen"
   },
   "source": [
    "### Creating a Test Set\n",
    "\n",
    "Models like the one we've created in this tutorial are designed to be used in the real world. It's common practice to set aside a small fraction of the data (e.g. 10%) just for testing and reporting the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-maria",
   "metadata": {
    "id": "french-maria"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-outreach",
   "metadata": {
    "id": "continental-outreach"
   },
   "outputs": [],
   "source": [
    "inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs, targets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-translation",
   "metadata": {
    "id": "existing-translation"
   },
   "outputs": [],
   "source": [
    "# Create and train the model\n",
    "model = LinearRegression().fit(inputs_train, targets_train)\n",
    "\n",
    "# Generate predictions\n",
    "predictions_test = model.predict(inputs_test)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets_test, predictions_test)\n",
    "print('Test Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-pride",
   "metadata": {
    "id": "smart-pride"
   },
   "source": [
    "Let's compare this with the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-mauritius",
   "metadata": {
    "id": "composite-mauritius"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions_train = model.predict(inputs_train)\n",
    "\n",
    "# Compute loss to evalute the model\n",
    "loss = rmse(targets_train, predictions_train)\n",
    "print('Training Loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-mouse",
   "metadata": {
    "id": "stainless-mouse"
   },
   "source": [
    "Can you explain why the training loss is lower than the test loss? We'll discuss this in a lot more detail in future tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-mambo",
   "metadata": {
    "id": "critical-mambo"
   },
   "source": [
    "### How to Approach a Machine Learning Problem\n",
    "\n",
    "Here's a strategy you can apply to approach any machine learning problem:\n",
    "\n",
    "1. Explore the data and find correlations between inputs and targets\n",
    "2. Pick the right model, loss functions and optimizer for the problem at hand\n",
    "3. Scale numeric variables and one-hot encode categorical data\n",
    "4. Set aside a test set (using a fraction of the training set)\n",
    "5. Train the model\n",
    "6. Make predictions on the test set and compute the loss\n",
    "\n",
    "We'll apply this process to several problems in future tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-scottish",
   "metadata": {
    "id": "theoretical-scottish"
   },
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "We've covered the following topics in this tutorial:\n",
    "\n",
    "- A typical problem statement for machine learning\n",
    "- Downloading and exploring a dataset for machine learning\n",
    "- Linear regression with one variable using Scikit-learn\n",
    "- Linear regression with multiple variables \n",
    "- Using categorical features for machine learning\n",
    "- Regression coefficients and feature importance\n",
    "- Creating a training and test set for reporting results\n",
    "\n",
    "Apply the techniques covered in this tutorial to the following datasets:\n",
    "\n",
    "- https://www.kaggle.com/vikrishnan/boston-house-prices\n",
    "- https://www.kaggle.com/sohier/calcofi\n",
    "- https://www.kaggle.com/budincsevity/szeged-weather \n",
    "\n",
    "\n",
    "Check out the following links to learn more about linear regression:\n",
    "\n",
    "- https://jovian.ai/aakashns/02-linear-regression\n",
    "- https://www.kaggle.com/hely333/eda-regression\n",
    "- https://www.youtube.com/watch?v=kHwlB_j7Hkc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "prescribed-found",
    "attended-arizona",
    "revised-fellow",
    "optical-property",
    "duplicate-insulin",
    "objective-slope",
    "personal-associate",
    "german-triangle",
    "encouraging-evaluation",
    "affiliated-quality",
    "jewish-draft",
    "jewish-heart",
    "waiting-witch",
    "legal-governor",
    "sitting-nitrogen",
    "international-denmark",
    "wireless-table",
    "competent-incentive",
    "expressed-boston",
    "rural-nitrogen",
    "critical-mambo",
    "theoretical-scottish"
   ],
   "name": "Copy of python-sklearn-linear-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
